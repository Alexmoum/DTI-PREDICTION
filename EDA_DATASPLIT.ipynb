{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "DATA EXPLORATION AND ANALYSIS\n",
    "="
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports\n",
    "------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure visualization aesthetics\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataset Loading\n",
    "--"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initial Data Inspection\n",
    "--"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "EDA\n",
    "="
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unique proteins and ligands in full dataset\n",
    "-"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ορισμός του μονοπατιού του αρχείου\n",
    "file_path = 'C:/Users/alexandra/PycharmProjects/GING_DIPLOMA/DeepEmbedding-DTI/dataset/dude/cleaned_dataset.txt'\n",
    "\n",
    "# Φόρτωση του αρχείου σε ένα DataFrame με διαχωριστικό διπλό κενό\n",
    "df = pd.read_csv(file_path, sep='\\s+', engine='python', header=None, names=['SMILES', 'Protein', 'Label'])\n",
    "# Αριθμός μοναδικών πρωτεϊνών\n",
    "unique_proteins = df['Protein'].nunique()\n",
    "print(f'Αριθμός μοναδικών πρωτεϊνών: {unique_proteins}')\n",
    "\n",
    "# Αριθμός μοναδικών SMILES\n",
    "unique_smiles = df['SMILES'].nunique()\n",
    "print(f'Αριθμός μοναδικών SMILES: {unique_smiles}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Label Distribution\n",
    "--"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Count of each label\n",
    "label_counts = df['Label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Label', data=df_cleaned)\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Protein Distribution\n",
    "--"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Count of samples per protein\n",
    "protein_counts = df_cleaned['Protein'].value_counts()\n",
    "\n",
    "# Visualization (Top 20 Proteins)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=protein_counts.head(20).index, y=protein_counts.head(20).values)\n",
    "\n",
    "# Suppress x-axis labels\n",
    "plt.xticks([])\n",
    "\n",
    "plt.title('Top 20 Proteins by Sample Count')\n",
    "plt.xlabel('Protein')  # You can keep this line if you want the label without ticks\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Protein vs Label Distribution\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "sns.countplot(x='Protein', hue='Label', data=df_cleaned, palette='Set2')\n",
    "plt.title('Label Distribution Across Proteins')\n",
    "plt.xlabel('Protein')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([])\n",
    "plt.legend(title='Label')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create the countplot\n",
    "ax = sns.countplot(x='Protein', hue='Label', data=df, palette='Set2')\n",
    "\n",
    "# Set the title and axis labels with increased font size\n",
    "plt.title('Label Distribution Across Proteins', fontsize=30)\n",
    "plt.xlabel('Protein', fontsize=30)\n",
    "plt.ylabel('Count', fontsize=30)\n",
    "\n",
    "# Increase the font size of the legend\n",
    "plt.legend(title='Label', fontsize=20, title_fontsize=20)\n",
    "\n",
    "# Increase the tick label size on the y-axis\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "# Remove x-axis ticks and labels since they are too dense\n",
    "plt.xticks([])\n",
    "\n",
    "# Adjust layout to prevent labels from overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Finding min and max lengths of protein seq \n",
    "=="
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with space-separated values\n",
    "df = pd.read_csv('C:/Users/alexandra/PycharmProjects/GING_DIPLOMA/DeepEmbedding-DTI/dataset/dude/cleaned_dataset.txt', \n",
    "                 sep=\"\\s+\", header=None, names=['SMILES', 'Protein', 'Label'])\n",
    "\n",
    "# Make sure the 'Protein' column contains strings (in case of any non-string values)\n",
    "df['Protein'] = df['Protein'].astype(str)\n",
    "\n",
    "# Calculate the lengths of each protein sequence\n",
    "sequence_lengths = df['Protein'].apply(len)\n",
    "\n",
    "# Find the minimum and maximum lengths\n",
    "min_length = sequence_lengths.min()\n",
    "max_length = sequence_lengths.max()\n",
    "\n",
    "# Find the shortest sequence (by sequence length)\n",
    "shortest_sequence = df['Protein'][sequence_lengths.idxmin()]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Minimum sequence length: {min_length}\")\n",
    "print(f\"Maximum sequence length: {max_length}\")\n",
    "print(f\"Shortest sequence: {shortest_sequence}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to your dataset\n",
    "file_path = 'C:/Users/alexandra/PycharmProjects/GING_DIPLOMA/DeepEmbedding-DTI/dataset/dude/cleaned_dataset.txt'\n",
    "\n",
    "# Initialize a set to store unique protein sequences\n",
    "unique_proteins = set()\n",
    "\n",
    "# Read the file and extract unique protein sequences\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) >= 2:\n",
    "            protein_sequence = parts[1]\n",
    "            unique_proteins.add(protein_sequence)\n",
    "\n",
    "# Calculate the length of each unique protein sequence\n",
    "sequence_lengths = [len(seq) for seq in unique_proteins]\n",
    "\n",
    "# Plotting the length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(sequence_lengths, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.title('Protein Sequence Length Distribution',fontsize=20)\n",
    "plt.xlabel('Sequence Length',fontsize=20)\n",
    "plt.ylabel('Frequency',fontsize=20)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Size of Dictionaries For the Complete Dataset\n",
    "-"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path='C:/Users/alexandra/PycharmProjects/GING_DIPLOMA/DeepEmbedding-DTI/dataset/dude/preprocessed_clean_dataset/fingerprint_dict.pickle'\n",
    "import pickle\n",
    "hd=open(file_path,'rb')\n",
    "inter=pickle.load(hd)\n",
    "print(len(inter))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path='C:/Users/alexandra/PycharmProjects/GING_DIPLOMA/DeepEmbedding-DTI/dataset/dude/preprocessed_clean_dataset/word_dict.pickle'\n",
    "\n",
    "import pickle\n",
    "file=open(file_path,'rb')\n",
    "data=pickle.load(file)\n",
    "print(len(data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Inspect the first sample in dataset_train to understand input shapes\n",
    "sample_data = dataset_test[0]\n",
    "\n",
    "# Extract individual components\n",
    "fingerprints, adjacency, words, inter = sample_data  # Assuming last element is label\n",
    "\n",
    "# Print shapes of each component to determine input dimensions\n",
    "print(\"Fingerprints shape:\", fingerprints.shape)\n",
    "print(\"Adjacency shape:\", adjacency.shape)\n",
    "print(\"Words shape:\", words.shape)\n",
    "print(\"Int shape:\", inter.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PROTEIN-CENTRIC SPLIT\n",
    "="
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Custom data split function 72 training 30 testing protein centric\n",
    "=="
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import sys\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "\n",
    "def load_tensor(file_name, dtype):\n",
    "    with open(file_name + '.pkl', 'rb') as f:\n",
    "        return [dtype(d).to(device) for d in pickle.load(f)]\n",
    "\n",
    "\n",
    "def load_pickle(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "dir_input = ('C:/Users/alexandra/PycharmProjects/GING_DIPLOMA/DeepEmbedding-DTI/dataset/dude/preprocessed_clean_dataset/')\n",
    "\n",
    "\"\"\"CPU or GPU.\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('The code uses GPU...')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('The code uses CPU!!!')\n",
    "\n",
    "compounds = load_tensor(dir_input + 'compounds', torch.LongTensor)\n",
    "adjacencies = load_tensor(dir_input + 'adjacencies', torch.FloatTensor)\n",
    "proteins = load_tensor(dir_input + 'proteins', torch.LongTensor)\n",
    "interactions = load_tensor(dir_input + 'interactions', torch.LongTensor)\n",
    "fingerprint_dict = load_pickle(dir_input + 'fingerprint_dict.pickle')\n",
    "word_dict = load_pickle(dir_input + 'word_dict.pickle')\n",
    "n_fingerprint = len(fingerprint_dict)\n",
    "n_word = len(word_dict)\n",
    "dataset = list(zip(compounds, adjacencies, proteins, interactions))\n",
    "def custom_split(dataset):\n",
    "    \"\"\"Create a dataset and split it into train/dev/test.\"\"\"\n",
    "    \n",
    "    # Step 1: Map each unique protein to its samples\n",
    "    protein_to_samples = defaultdict(list)\n",
    "    for i, (compound, adjacency, protein, interaction) in enumerate(dataset):\n",
    "        protein_to_samples[tuple(protein.tolist())].append((compound, adjacency, protein, interaction))\n",
    "    #print(protein_to_samples)\n",
    "        # Sort protein_to_samples by the number of samples for each protein in descending order\n",
    "    sorted_proteins = sorted(protein_to_samples.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "    \n",
    "    # Convert back to a dictionary, if you need the sorted dictionary\n",
    "    sorted_protein_to_samples = dict(sorted_proteins)\n",
    "\n",
    "    # Step 2: Split proteins into training, validation, and test sets\n",
    "    unique_proteins = list(sorted_protein_to_samples.keys())\n",
    "    random.seed(1234)\n",
    "    #random.shuffle(unique_proteins)\n",
    "    \n",
    "    # Select 72 proteins for training/validation and 30 for testing\n",
    "    train_val_proteins = unique_proteins[:72]\n",
    "    test_proteins = unique_proteins[72:]\n",
    "    \n",
    "    # Further split train_val_proteins into 80% training and 20% validation\n",
    "    train_size = int(len(train_val_proteins) * 0.8)\n",
    "    train_proteins = train_val_proteins[:train_size]\n",
    "    val_proteins = train_val_proteins[train_size:]\n",
    "    \n",
    "    # Step 3: Collect samples based on the protein split\n",
    "    dataset_train = [sample for protein in train_proteins for sample in sorted_protein_to_samples[protein]]\n",
    "    dataset_dev = [sample for protein in val_proteins for sample in sorted_protein_to_samples[protein]]\n",
    "    dataset_test = [sample for protein in test_proteins for sample in sorted_protein_to_samples[protein]]\n",
    "    return dataset_train,dataset_dev,dataset_test\n",
    "dataset_train,dataset_dev,dataset_test=custom_split(dataset)\n",
    "# Verify the size of each dataset\n",
    "print(f\"Training set: {len(dataset_train)} samples\")\n",
    "print(f\"Validation set: {len(dataset_dev)} samples\")\n",
    "print(f\"Test set: {len(dataset_test)} samples\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming `dataset_test` is a list of tuples as explained\n",
    "# Save the dataset as a PyTorch file\n",
    "torch.save(dataset_test, 'C:/Users/alexandra/PycharmProjects/GING_DIPLOMA/DeepEmbedding-DTI/dataset/dude/base_model/test_set_ex3.pt')\n",
    "torch.save(dataset_train, 'C:/Users/alexandra/PycharmProjects/GING_DIPLOMA/DeepEmbedding-DTI/dataset/dude/base_model/train_set_ex3.pt')\n",
    "torch.save(dataset_dev, 'C:/Users/alexandra/PycharmProjects/GING_DIPLOMA/DeepEmbedding-DTI/dataset/dude/base_model/dev_set_ex3.pt')\n",
    "\n",
    "print(\"Dataset saved successfully.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_test=torch.load('C:/Users/alexandra/PycharmProjects/GING_DIPLOMA/DeepEmbedding-DTI/dataset/dude/base_model/test_set_ex3.pt',weights_only=False)\n",
    "len(dataset_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "#dataset=torch.load('C:/Users/alexandra/PycharmProjects/GING_DIPLOMA/DeepEmbedding-DTI/dataset/dude/base_model/val_set_ex3.pt',weights_only=False)\n",
    "dataset=dataset_test\n",
    "# Υπολογισμός της κατανομής των labels στο training set\n",
    "def plot_label_distribution(dataset):\n",
    "    # Εξαγωγή των labels από το dataset\n",
    "    labels = [data[-1].item() for data in dataset]  # Αν το label είναι σε tensor, μετατρέψτε σε item\n",
    "    label_counts = Counter(labels)\n",
    "\n",
    "    # Εκτύπωση της κατανομής\n",
    "    print(\"Label Distribution in Training Set:\")\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"Label {label}: {count} samples\")\n",
    "\n",
    "    # Bar plot της κατανομής\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(label_counts.keys(), label_counts.values(), color='skyblue')\n",
    "    plt.xlabel(\"Labels\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Label Distribution in Training Set\")\n",
    "    plt.xticks(list(label_counts.keys()))  # Αν θέλουμε ονόματα κάτω από κάθε label\n",
    "    plt.show()\n",
    "\n",
    "# Κλήση της συνάρτησης\n",
    "plot_label_distribution(dataset)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}